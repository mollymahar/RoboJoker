{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import nltk\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.data import find\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import random\n",
    "\n",
    "data = pd.read_csv('./all_cc_jokes.csv', sep = ',', index_col = 0, names = ['type', 'link', 'text'])\n",
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
    "model = gensim.models.Word2Vec.load_word2vec_format(word2vec_sample, binary=False)\n",
    "tfidfvectorizer = TfidfVectorizer(max_features=2000, stop_words='english')\n",
    "tfidf_counts = tfidfvectorizer.fit_transform(data['text'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def latent_topic(joke_index, tfidf_counts, tfidfvectorizer, model):\n",
    "    \"\"\"creates a latent topic for a joke using an existing word2vec model\n",
    "    does so by doing a weighted avg of word2vec \"\"\"\n",
    "    print('\\rdoing joke {}'.format(joke_index), end='')\n",
    "    scores = tfidf_counts[joke_index]\n",
    "    result = None\n",
    "    for index in scores.indices:\n",
    "        curr_word = tfidfvectorizer.get_feature_names()[index]\n",
    "        try:\n",
    "            if result is None:\n",
    "                result = model[curr_word]\n",
    "            else:\n",
    "                result += model[curr_word]\n",
    "        except:\n",
    "            pass\n",
    "    return result\n",
    "\n",
    "def latent_topic2(joke_index, tfidf_counts, tfidfvectorizer, model):\n",
    "    \"\"\"creates a latent topic for a joke using an existing word2vec model\n",
    "    does so by doing a weighted avg of word2vec \"\"\"\n",
    "    print('\\rdoing joke {}'.format(joke_index), end='')\n",
    "    scores = tfidf_counts[joke_index]\n",
    "    result = None\n",
    "    for index in scores.indices:\n",
    "        curr_word = tfidfvectorizer.get_feature_names()[index]\n",
    "        try:\n",
    "            if result is None:\n",
    "                result = model[curr_word].reshape((1,300))\n",
    "            else:\n",
    "                result = np.append(result,model[curr_word], axis=0)\n",
    "        except:\n",
    "            pass\n",
    "    if result is None:\n",
    "        return None\n",
    "    mean = np.mean(result, axis=0)\n",
    "    std = np.std(result, axis=0)\n",
    "    return np.append(mean-std, mean+std, axis = 0).reshape((600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded latent topics for jokes from file\n"
     ]
    }
   ],
   "source": [
    "generate = False\n",
    "try:\n",
    "    all_latent_topics = np.load('./latent_topics2.npy')\n",
    "    print(\"successfully loaded latent topics for jokes from file\")\n",
    "except:\n",
    "    generate = True\n",
    "\n",
    "if generate:\n",
    "    print(\"generating latent topics for jokes file,\")\n",
    "    all_latent_topics = np.zeros((data.shape[0],300))\n",
    "    for i in range(data.shape[0]):\n",
    "        result = latent_topic(i, tfidf_counts, tfidfvectorizer, model)\n",
    "        if result is not None:\n",
    "            all_latent_topics[i] = result \n",
    "    print(\"done! saved as latent_topics.npy\")\n",
    "    np.save('./latent_topics.npy', all_latent_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14474\n",
      "Yo' Mama is so fat, I had to take a train and two buses just to get on her good side. \n",
      "skip, identical\n",
      "index 6021\n",
      "actual 60362000787.7\n",
      "ssd 0.0\n",
      "Every once in a while, I'll be walking around, going, 'Look at me! My clothes are kind of baggy. Maybe I am losing weight.' Turns out -- just laundry time. Maybe I shouldn't wear the same jeans six days in a row. \n",
      "skip, identical\n",
      "index 7797\n",
      "actual 551943133514.0\n",
      "ssd 0.0\n",
      "Guys can always be pigs. Guys can just do anything. You see guys walking along with their pants halfway down so you can see the crack of their butt. That's the good way to find a mechanic in the city. \n",
      "skip, identical\n",
      "index 4526\n",
      "actual 457487705.553\n",
      "ssd 0.0\n",
      "I met Hillary Clinton about seven months ago. Talk about strange bedfellows' right there. And we didn't even really talk to each other -- we kinda just stood next to each other at the urinal for a couple of minutes. \n",
      "skip, identical\n",
      "index 11552\n",
      "actual 551943133514.0\n",
      "ssd 0.0\n",
      "Our Supreme Court has even ruled that forcing one inmate to share a cell with another who smokes is cruel and unusual punishment. In other words, our justice has decided that a prisoner can still sodomize his cell mate, he just can't enjoy that come down cigarette afterward. \n",
      "skip, identical\n",
      "index 1452\n",
      "actual 116043970851.0\n",
      "ssd 0.0\n",
      "Q: Why are politicians proof of reincarnation?\r\n",
      " \r\n",
      " A: You just can't get that screwed up in one lifetime. \n",
      "skip, identical\n",
      "index 12624\n",
      "actual 1605.74886117\n",
      "ssd 0.0\n",
      "Three o'clock in the afternoon today, I'm downtown; there's a guy standing in front of a fire hydrant, which is open just a little bit. He's naked from the waist down, and in the spray from the hydrant, he's shaving off his pubic hair with a disposable razor. Nobody is even looking twice at this guy. And I'm thinking after seeing this: can I really worry about wearing white after Labor Day? \n",
      "skip, identical\n",
      "index 3004\n",
      "actual 26734408931.1\n",
      "ssd 0.0\n",
      "I tried cocaine to lose weight. It just made me eat faster. \n",
      "skip, identical\n",
      "index 11265\n",
      "actual 1091.0926345\n",
      "ssd 0.0\n",
      "Just in case you were wondering, yes, I can get my hands on all the free Viagra I want.\r\n",
      "  \n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "4492\n",
      "That's just what we need because humans haven't made up enough reasons to hate one another. Along with race, nationality, gender, sexual preference, religious or cultural differences -- now, if you're born in June, you're a prick. \n"
     ]
    }
   ],
   "source": [
    "def find_most_similar(index, latent_topics, jokes):\n",
    "    curr_topic = latent_topics[index]\n",
    "    \n",
    "    ssd = np.sum(np.abs(latent_topics - curr_topic), axis=1)\n",
    "    index = 0\n",
    "\n",
    "    while ssd[np.argsort(ssd)[index]] == 0 and index < 8:\n",
    "        print (\"skip, identical\")\n",
    "        print ('index', np.argsort(ssd)[index])\n",
    "        print ('actual', np.sum(np.square(latent_topics[index] - curr_topic)))\n",
    "        print ('ssd', ssd[np.argsort(ssd)[index]])\n",
    "        print (jokes[np.argsort(ssd)[index]])\n",
    "        index += 1\n",
    "    print (np.sum(np.square(latent_topics[np.argsort(ssd)[index]] - curr_topic)))\n",
    "    print(np.sum(np.square(latent_topics - curr_topic), axis=1)[np.argsort(ssd)[index]])\n",
    "    print (ssd[np.argsort(ssd)[index]])\n",
    "    print (ssd[np.argsort(ssd)[index+1]])\n",
    "    print (ssd[np.argsort(ssd)[index-1]])\n",
    "\n",
    "    return np.argsort(ssd)[index]\n",
    "\n",
    "# set to random, or you can set index to a number\n",
    "index=random.randint(0,data.shape[0])\n",
    "# index=13929\n",
    "print(index)\n",
    "print (data['text'][index])\n",
    "similar_index = find_most_similar(index, all_latent_topics, data['text'])\n",
    "print(similar_index)\n",
    "print (data['text'][similar_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  13614\n",
      "rating:  2.70885298667\n",
      "A blonde was taking helicopter lessons. The instructor said, \"I'll radio you every 1,000 feet to see how you're doing.\"\r\n",
      " At 1,000 feet, the instructor radioed her and said she was doing great. At 2,000 feet, he said she was still doing well.\r\n",
      " \r\n",
      " Right before she got to 3,000 feet, the propeller stopped, and she twirled to the ground. The instructor ran to where she crashed and pulled her out of the helicopter. He asked her, \"What went wrong?\"\r\n",
      " \r\n",
      " The blonde said, \"At 2,500 feet, I started to get cold, so I turned the big fan off.\" \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn import linear_model\n",
    "\n",
    "def guess_ratings(indices, ratings, joke_features):\n",
    "    alpha = 9999999999\n",
    "#     lasso =linear_model.LinearRegression()\n",
    "#     lasso = Lasso(alpha=alpha, max_iter = 20000, tol=.1)\n",
    "    lasso = linear_model.Ridge (alpha = .1)\n",
    "#     lasso = ElasticNet(alpha=alpha, l1_ratio=0.7, max_iter=20000)\n",
    "#     lasso\n",
    "\n",
    "    y_pred_lasso = lasso.fit(joke_features[indices], ratings).predict(joke_features)\n",
    "    y_pred_lasso -= np.mean(y_pred_lasso)\n",
    "    y_pred_lasso *= 1.5/np.std(y_pred_lasso)\n",
    "    y_pred_lasso += 2.5\n",
    "    return y_pred_lasso\n",
    "# add a joke's index and then its corresponding rating \n",
    "indices = [9539, 9943, 14327, 14328, 13048, 13058, 8698, 8701, 2578, 2598, 5497, 6235, 13886, 0, 15017, 13882, 10817, 13867, 14196, 13860, 13857, 10764, 13876, 10830, 10820, 13894, 13889, 13864, 13893, 14086, 13871, 13874, 12070, 13861, 13829, 13871, 12806, 12916, 14609, 14506, 14232, 13892, 13896, 13052, 13078, 4479, 10665, 3220, 5178, 4971, 10065, 14513, 4851, 14453, 14406, 14427, 221, 1399, 9912, 294, 9192, 130, 9960, 5156, 14276, 10745, 10175, 14434]\n",
    "ratings = [4.5, 2, 3.3, 4, 5, 2, 3.8, 3, 2, 4, 3.5, 1, 3, 4, 3.5, 3, 0, 1, .5, 0, 2, 1, 0, 4, 4.5, 4.5, 2, 3, 3, 1, 2, 4, 1, 4, 2, 3, 4, 0, 4, 1, 2.1, 1, 2, 0, 0, 0, 5, 3, 4.5, 5, 1, 3.3, 3.4, 3, 3, 1, 0, 0, 0, 3, 2, 3, 1, 3, 2, 2, 2, 5]\n",
    "indices, ratings = np.asarray(indices), np.asarray(ratings)\n",
    "guesses = guess_ratings(indices, ratings, all_latent_topics)\n",
    "\n",
    "# uncomment this to get \"good jokes\"\n",
    "# blah = random.randint(-1000, -1)\n",
    "\n",
    "# uncomment this to get \"bad jokes\"\n",
    "# blah = random.randint(0, 1000)\n",
    "\n",
    "# uncomment this to get a completely random joke\n",
    "blah = random.randint(0, 15000)\n",
    "\n",
    "\n",
    "joke_index = np.argsort(guesses)[blah]\n",
    "while joke_index in indices:\n",
    "    blah -= 1\n",
    "    joke_index = np.argsort(guesses)[blah]\n",
    "# joke_index = random.randint(0, 15000)\n",
    "print('index: ', joke_index)\n",
    "print('rating: ', guesses[joke_index])\n",
    "print(data['text'][joke_index])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py3k]",
   "language": "python",
   "name": "Python [py3k]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
